{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The command pd.options.display.max_colwidth = 100 prints the number of characters.\n",
    "Change to see th number of characters while printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing packages and data to kernel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "xcel = pd.ExcelFile('train_data.xls')\n",
    "df = xcel.parse(\"Sheet1\", encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below the length is 1000 and hence it has printed first 1000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thanks for writing in Suriyah. \\n\\nWe can do a Skype call mid/late next week to discuss.\\n\\nHarpreet will help schedule, pls. be in touch with her.\\n\\n \\n\\nRegards,\\n\\n \\n\\nSoumya\\n\\n \\n\\nFrom: Suriyah Krishnan [mailto:suriyah@contractiq.com] \\nSent: 13 November 2015 14:30\\nTo: Soumya &lt;soumya@easyrewardz.com&gt;\\nSubject: Scaling Engineering Teams\\n\\n \\n\\nHi Soumya, \\n\\nI came across your profile while looking for product owners / CTOs in my network. \\n\\n \\n\\nI thought I'd share a report we had published recently on  &lt;http://sendy.contractiq.com/l/rprLsFiRhGXvhwJEkYo3892w/rL4EXOKehCBO1nID7gwJlA/FL00s0cffBMfFAvhIX3wxQ&gt; Apps, SDKs &amp; pricing trends. \\n\\n \\n\\nOn the same note, we match high growth startups with elite dev shops that help scale products. Portfolio companies of YC, a16z, Sequoia, Accel and several large private companies take our help in finding elite dev partners. \\n\\n \\n\\nIs this of interest? If yes, can we speak briefly on Monday sometime post 2.30 PM IST? \\n\\nBest, \\n\\nS...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi Suriyah!\\nThanks fir reaching out! I would be happy to talk but let's schedule a call for next week! Wednesday 11am could work!\\nBest, Peter\\n\\nSent from my iPhone\\n\\n&gt; On Jun 9, 2015, at 2:10 PM, Suriyah Krishnan &lt;suriyah@contractiq.com&gt; wrote:\\n</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi Suriyah –\\n\\nI’m not really a decision maker here at Oracle. Your best bet would be to contact Oracle directly.\\n\\n \\n\\nJill\\n\\n \\n\\nFrom: Suriyah Krishnan [mailto:suriyah@contractiq.com] \\nSent: Tuesday, July 08, 2014 12:30 PM\\nTo: Jill\\nSubject: Can we speak?\\n\\n \\n\\nHello Jill, \\n\\nI had found you on LinkedIn while looking for those that are in the social, mobile, analytics intersection. \\n\\nWe're a HYPERLINK \"http://sendy.contractiq.com/l/sDi1HV2F90PCEU3Cj8z7cw/JXaPZGqajd6mGFwLh763Qnlg/4f892riMVhtN6kQW19PPx4Yg\"highly personalized &amp; free curation service called ContractIQ. We track over 2500 mobile &amp; web product outsourcing teams and identify the top 2%. We then hand-curate introductions to CIOs &amp; CTOs that are looking for teams with relevant experience and credentials. \\n\\n \\n\\nThe idea is to make critical product engineering outsourcing initiatives, a frustration free experience. \\n\\n \\n\\nIf what we do would be relevant for you now or in the future, could we plan for a shor...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi Suriyah,\\n\\nPlease reach out end of second quarter and I'll make some time to discuss.\\n\\nRight now we are focused on a major sprint and not spending any more budget\\non anything.\\n\\nThanks\\n\\nJason\\n\\nOn Mon, Jan 19, 2015 at 1:52 PM, Suriyah Krishnan &lt;suriyah@contractiq.com&gt;\\nwrote:\\n</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am currently out of the office and will have limited e-Mail connectivity until I return on Tuesday 23rd September. I will attend to your message at the earliest opportunity.\\n\\nKind regards\\nAshley Sowerby I Managing Director I Chevin Fleet Solutions / Nathan Grace Holdings\\n\\n\\nTo learn more about Chevin's flexible fleet management solutions, take a moment to view this three minute video&lt;http://www.chevinfleet.com.au/movie&gt;\\n\\nThis email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are addressed. If you have received this email in error please notify the originator of the message. Any views expressed in this message are those of the individual sender, except where the sender specifies and with authority, states them to be the views of Chevin Fleet Solutions. Please be aware that emails sent to or received from Chevin Fleet Solutions may be intercepted and read by Chevin Fleet Solutions. Interception w...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  Thanks for writing in Suriyah. \\n\\nWe can do a Skype call mid/late next week to discuss.\\n\\nHarpreet will help schedule, pls. be in touch with her.\\n\\n \\n\\nRegards,\\n\\n \\n\\nSoumya\\n\\n \\n\\nFrom: Suriyah Krishnan [mailto:suriyah@contractiq.com] \\nSent: 13 November 2015 14:30\\nTo: Soumya <soumya@easyrewardz.com>\\nSubject: Scaling Engineering Teams\\n\\n \\n\\nHi Soumya, \\n\\nI came across your profile while looking for product owners / CTOs in my network. \\n\\n \\n\\nI thought I'd share a report we had published recently on  <http://sendy.contractiq.com/l/rprLsFiRhGXvhwJEkYo3892w/rL4EXOKehCBO1nID7gwJlA/FL00s0cffBMfFAvhIX3wxQ> Apps, SDKs & pricing trends. \\n\\n \\n\\nOn the same note, we match high growth startups with elite dev shops that help scale products. Portfolio companies of YC, a16z, Sequoia, Accel and several large private companies take our help in finding elite dev partners. \\n\\n \\n\\nIs this of interest? If yes, can we speak briefly on Monday sometime post 2.30 PM IST? \\n\\nBest, \\n\\nS...   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Hi Suriyah!\\nThanks fir reaching out! I would be happy to talk but let's schedule a call for next week! Wednesday 11am could work!\\nBest, Peter\\n\\nSent from my iPhone\\n\\n> On Jun 9, 2015, at 2:10 PM, Suriyah Krishnan <suriyah@contractiq.com> wrote:\\n   \n",
       "2  Hi Suriyah –\\n\\nI’m not really a decision maker here at Oracle. Your best bet would be to contact Oracle directly.\\n\\n \\n\\nJill\\n\\n \\n\\nFrom: Suriyah Krishnan [mailto:suriyah@contractiq.com] \\nSent: Tuesday, July 08, 2014 12:30 PM\\nTo: Jill\\nSubject: Can we speak?\\n\\n \\n\\nHello Jill, \\n\\nI had found you on LinkedIn while looking for those that are in the social, mobile, analytics intersection. \\n\\nWe're a HYPERLINK \"http://sendy.contractiq.com/l/sDi1HV2F90PCEU3Cj8z7cw/JXaPZGqajd6mGFwLh763Qnlg/4f892riMVhtN6kQW19PPx4Yg\"highly personalized & free curation service called ContractIQ. We track over 2500 mobile & web product outsourcing teams and identify the top 2%. We then hand-curate introductions to CIOs & CTOs that are looking for teams with relevant experience and credentials. \\n\\n \\n\\nThe idea is to make critical product engineering outsourcing initiatives, a frustration free experience. \\n\\n \\n\\nIf what we do would be relevant for you now or in the future, could we plan for a shor...   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Hi Suriyah,\\n\\nPlease reach out end of second quarter and I'll make some time to discuss.\\n\\nRight now we are focused on a major sprint and not spending any more budget\\non anything.\\n\\nThanks\\n\\nJason\\n\\nOn Mon, Jan 19, 2015 at 1:52 PM, Suriyah Krishnan <suriyah@contractiq.com>\\nwrote:\\n   \n",
       "4  I am currently out of the office and will have limited e-Mail connectivity until I return on Tuesday 23rd September. I will attend to your message at the earliest opportunity.\\n\\nKind regards\\nAshley Sowerby I Managing Director I Chevin Fleet Solutions / Nathan Grace Holdings\\n\\n\\nTo learn more about Chevin's flexible fleet management solutions, take a moment to view this three minute video<http://www.chevinfleet.com.au/movie>\\n\\nThis email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are addressed. If you have received this email in error please notify the originator of the message. Any views expressed in this message are those of the individual sender, except where the sender specifies and with authority, states them to be the views of Chevin Fleet Solutions. Please be aware that emails sent to or received from Chevin Fleet Solutions may be intercepted and read by Chevin Fleet Solutions. Interception w...   \n",
       "\n",
       "      class  \n",
       "0  Positive  \n",
       "1  Positive  \n",
       "2   Neutral  \n",
       "3  Negative  \n",
       "4   Neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking a look at first five rows of data\n",
    "pd.options.display.max_colwidth = 1000\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below the length is 100 and it has printed first 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thanks for writing in Suriyah. \\n\\nWe can do a Skype call mid/late next week to discuss.\\n\\nHarp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi Suriyah!\\nThanks fir reaching out! I would be happy to talk but let's schedule a call for nex...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi Suriyah –\\n\\nI’m not really a decision maker here at Oracle. Your best bet would be to contac...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi Suriyah,\\n\\nPlease reach out end of second quarter and I'll make some time to discuss.\\n\\nRig...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am currently out of the office and will have limited e-Mail connectivity until I return on Tue...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  Thanks for writing in Suriyah. \\n\\nWe can do a Skype call mid/late next week to discuss.\\n\\nHarp...   \n",
       "1  Hi Suriyah!\\nThanks fir reaching out! I would be happy to talk but let's schedule a call for nex...   \n",
       "2  Hi Suriyah –\\n\\nI’m not really a decision maker here at Oracle. Your best bet would be to contac...   \n",
       "3  Hi Suriyah,\\n\\nPlease reach out end of second quarter and I'll make some time to discuss.\\n\\nRig...   \n",
       "4  I am currently out of the office and will have limited e-Mail connectivity until I return on Tue...   \n",
       "\n",
       "      class  \n",
       "0  Positive  \n",
       "1  Positive  \n",
       "2   Neutral  \n",
       "3  Negative  \n",
       "4   Neutral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = df.iloc[4]\n",
    "type(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Negative    592\n",
       "Neutral     297\n",
       "Positive    111\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets count the number of records in each class\n",
    "df.groupby(['class'])['text'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHI1JREFUeJzt3XucXWV97/HPFwIJIBBCEi5JIAIB\nxFYh5mAAbSlYCwEJVaigQEjjSaloy1Grqee8PNriAU5RLqLYKJeAXEIRJEC0xEBQ0ACTGi4hQAZM\nSUxIBkICiFASfv3jeUa2k2dm9oRZs+fyfb9e+7XX5Vlr/dbeyf7OetbeaykiMDMza2urRhdgZma9\nkwPCzMyKHBBmZlbkgDAzsyIHhJmZFTkgzMysyAFh3U7SckkfatC2d5P0M0kvS/pGI2qoqeUVSfvk\n4aslnft21tEbSFog6VO9ZT1WrUGNLsCsm00Hngd2igb/yCci3tEb1mG2pXwEYb2WpC35A2Zv4PFG\nh4NZf+CAGCByt88XJD0iaYOk2ZKG5HlnSrqvTfuQtF8evlrSdyT9OHd53C9pd0kXS3pR0hOSDmmz\nyf8h6fE8/6rWbeX1HS9psaT1kn4h6T1t6vySpEeA35ZCQtLhkh7K+/GQpMNb6wSmAF/MdW7WzSVp\nsKQLJT0raY2k70raLs87UtJKSV+UtFbSakknSpok6SlJ6yR9uWZdh0r6Zd6P1ZIuk7Rt6TVsU8Nw\nSXfk5dZJ+rmk4v/FwvvwbUl35i60ByTtW1out5+YX9/1kh6WdGTNvKmSlub1PCPpb9osOzm/Ry9J\nelrSMTWz987/Bl6WdJek4R3U0NF6WtvsK+luSS9Iel7SdZKG1sz/kqTf5O09KenoPP1QSU153Wsk\nfbO9OmwLRYQfA+ABLAceBPYEhgFLgbPyvDOB+9q0D2C/PHw1qdvmfcAQ4G7g18AZwNbAucA9bbb1\nGDAmb+t+4Nw8bzywFnh/XnZKbj+4ZtnFedntCvsxDHgROJ3URXpqHt+1ptZzO3gdLgbm5PXsCNwO\nnJfnHQlsBL4CbAP8T6AFuD63fTfwGrBPbv8+YGKuY2x+Tc/p4DVsfQ3OA76bt7EN8EFA7dTbdh3r\ngEPzNq8DbmxnuVHAC8Ak0h+Cf57HR+T5xwH7AgL+FHgVGJ/nHQpsyMtsldd1YJ63AHga2B/YLo+f\n304Nna3nU3l4v9xmMDAC+BlwcZ53ALAC2DOPjwX2zcO/BE7Pw+8AJjb6/1l/e/gIYmC5NCJWRcQ6\n0gfjwV1Y9taIWBQRrwG3Aq9FxDURsQmYDbQ9grgsIlbkbX2d9EEO6UP3XyPigYjYFBGzgNdJH7S1\nda6IiN8V6jgOWBYR10bExoi4AXgC+EhnOyBJefv/KyLWRcTLwP8DTqlp9gbw9Yh4A7gRGA5cEhEv\nR8QSYAnwHoD8eizMdSwH/pX0YduZN4A9gL0j4o2I+HnkT7k63BIRD0bERlJAtPcengbMjYi5EfFm\nRMwDmkiBQUTcGRFPR3IvcBcpqACmAVdGxLy87G8i4omadV8VEU/l9+emDmrobD3kWppzm9cjogX4\nJm+9jptIwXGQpG0iYnlEPJ3nvQHsJ2l4RLwSEQs7e/GsaxwQA8tzNcOvkv7qqteamuHfFcbbrmtF\nzfB/ko5cIJ0j+Hzu9lgvaT3paGHPdpZta8+8vlr/SfrrtDMjgO2BRTXb/kme3uqFHHqQ9gva2VdJ\n++euouckvUQKm3a7W2r8C9AM3JW7d2bUsUyret/DvYGT27zOHyAFE5KOlbQwd3GtJwVHa+1jSEcJ\nb7eGztZDrmWkpBtzN9JLwA9aa4mIZuAc4KvA2tyu9d/KNNKRzBO5q/H4zrZlXeOAMIDfkj44AZC0\nezesc0zN8F7Aqjy8gvQX+tCax/b5SKBVR39NryJ9+NXaC/hNHTU9T/qAf3fNtneOLf+m0OWko5dx\nEbET8GVSl02H8tHI5yNiH9KRz+da+9W70Qrg2jav8w4Rcb6kwcAPgQuB3SJiKDC3pvYVpO6n7qih\nnvWcR3rP35Nfx9NqaiEiro+ID5De9wAuyNOXRcSpwMg87WZJO3RD3ZY5IAzgYeDdkg5WOpn81W5Y\n59mSRksaRvrgnJ2nfw84S9L7lewg6ThJO9a53rnA/pI+IWmQpI8DBwF3dLZgRLyZt3+RpJEAkkZJ\n+ouu7ly2I/AS8IqkA4G/rWchpZP0++Uur5dI3SibOlmsq34AfETSX0jaWtIQpZPwo4FtSd02LcBG\nSccCH65Z9gpgqqSjJW2VX6MDt6CGetezI/AKsF7SKOAfWmdIOkDSUTnUXiMF/KY87zRJI/L7uj4v\n0t2v44DmgDAi4ingn4CfAsuA+zpeoi7Xk/q1n8mPc/O2mkjnAS4jnVxuJp0kr7fWF4Djgc+TTrp+\nETg+Ip6vcxVfyttcmLszfko6EbolvgB8AniZFDyzO27+e+Pydl8hnWj9TkQs2MIaiiJiBTCZFM4t\npL/m/wHYKp97+TvS+YMXSfswp2bZB4GpwEWkk8z3svlRWz011Luer5G+vLABuBO4pWbeYOB80tHf\nc6SjhdZvkh0DLJH0CnAJcEo+R2bdRPWfGzMzs4HERxBmZlbkgDAzsyIHhJmZFTkgzMysqE9fzXX4\n8OExduzYRpdhZtanLFq06PmIGNFZuz4dEGPHjqWpqanRZZiZ9SmS2l6NoMhdTGZmVuSAMDOzIgeE\nmZkVVRoQkoZKulnphjJLJR0maZikeZKW5eddcltJulRSs9JNbcZXWZuZmXWs6iOIS4CfRMSBwHtJ\nN1SZAcyPiHHA/DwOcCzpGjXjSPcVvrzi2szMrAOVBYSknYA/IV3RkYj4r4hYT7qA2KzcbBZwYh6e\nDFyTb2CyEBgqaY+q6jMzs45VeQSxD+kqkldJ+pWk7+drte8WEasB8vPI3H4Uf3ijmJUUbgIjaXq+\nD21TS0tLheWbmQ1sVQbEINIlfC+PiENIN6Xp6M5ZpRutbHap2YiYGRETImLCiBGd/s7DzMy2UJUB\nsRJYGREP5PGbSYGxprXrKD+vrWlfexey0bx1FzIzM+thlf2SOiKek7RC0gER8SRwNPB4fkwh3QRk\nCnBbXmQO8BlJNwLvBza0dkVVYeyMO6ta9YC3/PzjGl2CmXWDqi+18VngOknbku4qNpV01HKTpGnA\ns8DJue1c0o3Tm0k3Qp9acW1mZtaBSgMiIhYDEwqzNrtBe6Rb251dZT1mZlY//5LazMyKHBBmZlbk\ngDAzsyIHhJmZFTkgzMysyAFhZmZFDggzMytyQJiZWZEDwszMihwQZmZW5IAwM7MiB4SZmRU5IMzM\nrMgBYWZmRQ4IMzMrckCYmVmRA8LMzIocEGZmVuSAMDOzIgeEmZkVOSDMzKzIAWFmZkUOCDMzK3JA\nmJlZkQPCzMyKHBBmZlZUaUBIWi7pUUmLJTXlacMkzZO0LD/vkqdL0qWSmiU9Iml8lbWZmVnHeuII\n4s8i4uCImJDHZwDzI2IcMD+PAxwLjMuP6cDlPVCbmZm1oxFdTJOBWXl4FnBizfRrIlkIDJW0RwPq\nMzMzqg+IAO6StEjS9Dxtt4hYDZCfR+bpo4AVNcuuzNP+gKTpkpokNbW0tFRYupnZwDao4vUfERGr\nJI0E5kl6ooO2KkyLzSZEzARmAkyYMGGz+WZm1j0qPYKIiFX5eS1wK3AosKa16yg/r83NVwJjahYf\nDayqsj4zM2tfZQEhaQdJO7YOAx8GHgPmAFNysynAbXl4DnBG/jbTRGBDa1eUmZn1vCq7mHYDbpXU\nup3rI+Inkh4CbpI0DXgWODm3nwtMApqBV4GpFdZmZmadqCwgIuIZ4L2F6S8ARxemB3B2VfWYmVnX\n+JfUZmZW5IAwM7MiB4SZmRU5IMzMrMgBYWZmRQ4IMzMrckCYmVmRA8LMzIocEGZmVuSAMDOzIgeE\nmZkVOSDMzKzIAWFmZkUOCDMzK3JAmJlZkQPCzMyKHBBmZlbkgDAzsyIHhJmZFTkgzMysyAFhZmZF\nDggzMytyQJiZWZEDwszMihwQZmZW5IAwM7OiygNC0taSfiXpjjz+TkkPSFomabakbfP0wXm8Oc8f\nW3VtZmbWvp44gvh7YGnN+AXARRExDngRmJanTwNejIj9gItyOzMza5BKA0LSaOA44Pt5XMBRwM25\nySzgxDw8OY+T5x+d25uZWQNUfQRxMfBF4M08viuwPiI25vGVwKg8PApYAZDnb8jt/4Ck6ZKaJDW1\ntLRUWbuZ2YBWWUBIOh5YGxGLaicXmkYd896aEDEzIiZExIQRI0Z0Q6VmZlYyqMJ1HwGcIGkSMATY\niXREMVTSoHyUMBpYlduvBMYAKyUNAnYG1lVYn5mZdaCyI4iI+MeIGB0RY4FTgLsj4pPAPcBJudkU\n4LY8PCePk+ffHRGbHUGYmVnPaMTvIL4EfE5SM+kcwxV5+hXArnn654AZDajNzMyyKruYfi8iFgAL\n8vAzwKGFNq8BJ/dEPWZm1jn/ktrMzIocEGZmVuSAMDOzIgeEmZkVOSDMzKzIAWFmZkUOCDMzK3JA\nmJlZkQPCzMyKHBBmZlbkgDAzsyIHhJmZFTkgzMysyAFhZmZFdQWEpPn1TDMzs/6jw/tBSBoCbA8M\nl7QLb903eidgz4prMzOzBurshkF/A5xDCoNFvBUQLwHfrrAuMzNrsA4DIiIuAS6R9NmI+FYP1WRm\nZr1AXbccjYhvSTocGFu7TERcU1FdZmbWYHUFhKRrgX2BxcCmPDkAB4SZWT9VV0AAE4CDIiKqLMbM\nzHqPen8H8Riwe5WFmJlZ71LvEcRw4HFJDwKvt06MiBMqqcrMzBqu3oD4apVFmJlZ71Pvt5jurboQ\nMzPrXer9FtPLpG8tAWwLbAP8NiJ2qqowMzNrrLpOUkfEjhGxU34MAT4GXNbRMpKGSHpQ0sOSlkj6\nWp7+TkkPSFomabakbfP0wXm8Oc8f+/Z2zczM3o4tupprRPwIOKqTZq8DR0XEe4GDgWMkTQQuAC6K\niHHAi8C03H4a8GJE7AdclNuZmVmD1NvF9NGa0a1Iv4vo8DcR+TcTr+TRbfIjSMHyiTx9FukE+OXA\nZN46GX4zcJkk+bcXZmaNUe+3mD5SM7wRWE76QO+QpK1JF/nbj3Rxv6eB9RGxMTdZCYzKw6OAFQAR\nsVHSBmBX4Pk265wOTAfYa6+96izfzMy6qt5vMU3dkpVHxCbgYElDgVuBd5Wa5Wd1MK92nTOBmQAT\nJkzw0cUAMnbGnY0uod9afv5xjS7BeqF6bxg0WtKtktZKWiPph5JG17uRiFgPLAAmAkMltQbTaGBV\nHl4JjMnbGwTsDKyrdxtmZta96j1JfRUwh3RfiFHA7XlauySNyEcOSNoO+BCwFLgHOCk3mwLclofn\n5HHy/Lt9/sHMrHHqPQcxIiJqA+FqSed0sswewKx8HmIr4KaIuEPS48CNks4FfgVckdtfAVwrqZl0\n5HBK3XthZmbdrt6AeF7SacANefxU4IWOFoiIR4BDCtOfAQ4tTH8NOLnOeszMrGL1djH9NfBXwHPA\nalIX0BaduDYzs76h3iOIfwamRMSLAJKGAReSgsPMzPqheo8g3tMaDgARsY5C95GZmfUf9QbEVpJ2\naR3JRxD1Hn2YmVkfVO+H/DeAX0i6mfTjtb8Cvl5ZVWZm1nD1/pL6GklNpOsoCfhoRDxeaWVmZtZQ\ndXcT5UBwKJiZDRBbdLlvMzPr/xwQZmZW5IAwM7MiB4SZmRU5IMzMrMgBYWZmRQ4IMzMrckCYmVmR\nA8LMzIocEGZmVuSAMDOzIgeEmZkVOSDMzKzIAWFmZkUOCDMzK3JAmJlZkQPCzMyKHBBmZlbkgDAz\ns6LKAkLSGEn3SFoqaYmkv8/Th0maJ2lZft4lT5ekSyU1S3pE0viqajMzs85VeQSxEfh8RLwLmAic\nLekgYAYwPyLGAfPzOMCxwLj8mA5cXmFtZmbWicoCIiJWR8R/5OGXgaXAKGAyMCs3mwWcmIcnA9dE\nshAYKmmPquozM7OO9cg5CEljgUOAB4DdImI1pBABRuZmo4AVNYutzNParmu6pCZJTS0tLVWWbWY2\noFUeEJLeAfwQOCciXuqoaWFabDYhYmZETIiICSNGjOiuMs3MrI1KA0LSNqRwuC4ibsmT17R2HeXn\ntXn6SmBMzeKjgVVV1mdmZu2r8ltMAq4AlkbEN2tmzQGm5OEpwG0108/I32aaCGxo7YoyM7OeN6jC\ndR8BnA48KmlxnvZl4HzgJknTgGeBk/O8ucAkoBl4FZhaYW1mZtaJygIiIu6jfF4B4OhC+wDOrqoe\nMzPrGv+S2szMihwQZmZW5IAwM7MiB4SZmRU5IMzMrMgBYWZmRQ4IMzMrckCYmVmRA8LMzIocEGZm\nVuSAMDOzIgeEmZkVOSDMzKzIAWFmZkUOCDMzK3JAmJlZkQPCzMyKHBBmZlbkgDAzsyIHhJmZFTkg\nzMysyAFhZmZFDggzMytyQJiZWZEDwszMigY1ugAz67/Gzriz0SX0W8vPP67ybVR2BCHpSklrJT1W\nM22YpHmSluXnXfJ0SbpUUrOkRySNr6ouMzOrT5VdTFcDx7SZNgOYHxHjgPl5HOBYYFx+TAcur7Au\nMzOrQ2UBERE/A9a1mTwZmJWHZwEn1ky/JpKFwFBJe1RVm5mZda6nT1LvFhGrAfLzyDx9FLCipt3K\nPG0zkqZLapLU1NLSUmmxZmYDWW/5FpMK06LUMCJmRsSEiJgwYsSIissyMxu4ejog1rR2HeXntXn6\nSmBMTbvRwKoers3MzGr0dEDMAabk4SnAbTXTz8jfZpoIbGjtijIzs8ao7HcQkm4AjgSGS1oJ/F/g\nfOAmSdOAZ4GTc/O5wCSgGXgVmFpVXWZmVp/KAiIiTm1n1tGFtgGcXVUtZmbWdb3lJLWZmfUyDggz\nMytyQJiZWZEDwszMihwQZmZW5IAwM7MiB4SZmRU5IMzMrMgBYWZmRQ4IMzMrckCYmVmRA8LMzIoc\nEGZmVuSAMDOzIgeEmZkVOSDMzKzIAWFmZkUOCDMzK3JAmJlZkQPCzMyKHBBmZlbkgDAzsyIHhJmZ\nFTkgzMysyAFhZmZFDggzMyvqVQEh6RhJT0pqljSj0fWYmQ1kvSYgJG0NfBs4FjgIOFXSQY2tysxs\n4Oo1AQEcCjRHxDMR8V/AjcDkBtdkZjZgDWp0ATVGAStqxlcC72/bSNJ0YHoefUXSkzWzhwPPV1Zh\nY/WZfdMFXWreZ/ari/rUfvk9A/rYfr3N92zvehbqTQGhwrTYbELETGBmcQVSU0RM6O7CeoP+um/e\nr76nv+5bf90v2PJ9601dTCuBMTXjo4FVDarFzGzA600B8RAwTtI7JW0LnALMaXBNZmYDVq/pYoqI\njZI+A/w7sDVwZUQs6eJqil1P/UR/3TfvV9/TX/etv+4XbOG+KWKzbn4zM7Ne1cVkZma9iAPCzMyK\n+nRASDpZ0hJJb0pq9ytckpZLelTSYklNPVnjlurCvvWpy5NIGiZpnqRl+XmXdtptyu/XYkm99ssK\nnb3+kgZLmp3nPyBpbM9XuWXq2LczJbXUvE+fakSdXSHpSklrJT3WznxJujTv8yOSxvd0jVuqjn07\nUtKGmvfrK52uNCL67AN4F3AAsACY0EG75cDwRtfb3ftGOpn/NLAPsC3wMHBQo2vvZL/+PzAjD88A\nLmin3SuNrrWOfen09Qc+DXw3D58CzG503d24b2cClzW61i7u158A44HH2pk/Cfgx6XdZE4EHGl1z\nN+7bkcAdXVlnnz6CiIilEfFk5y37njr3rS9enmQyMCsPzwJObGAtb1c9r3/t/t4MHC2p9KPQ3qYv\n/tvqVET8DFjXQZPJwDWRLASGStqjZ6p7e+rYty7r0wHRBQHcJWlRvlRHf1G6PMmoBtVSr90iYjVA\nfh7ZTrshkpokLZTUW0Okntf/920iYiOwAdi1R6p7e+r9t/Wx3BVzs6Qxhfl9TV/8P9UVh0l6WNKP\nJb27s8a95ncQ7ZH0U2D3wqz/HRG31bmaIyJilaSRwDxJT+S0bahu2Le6Lk/S0zrary6sZq/8nu0D\n3C3p0Yh4unsq7Db1vP698j2qQz113w7cEBGvSzqLdKR0VOWVVauvvl/1+A9g74h4RdIk4EfAuI4W\n6PUBEREf6oZ1rMrPayXdSjp8bnhAdMO+9crLk3S0X5LWSNojIlbnQ/e17ayj9T17RtIC4BBSn3hv\nUs/r39pmpaRBwM50czdARTrdt4h4oWb0e0DXLh/XO/XK/1PdISJeqhmeK+k7koZHRLsXKOz3XUyS\ndpC0Y+sw8GGgeJa/D+qLlyeZA0zJw1OAzY6UJO0iaXAeHg4cATzeYxXWr57Xv3Z/TwLujnzGsJfr\ndN/a9M2fACztwfqqMgc4I3+baSKwobVLtK+TtHvr+S9Jh5I+/1/ocKFGn3l/m2ft/5KU+K8Da4B/\nz9P3BObm4X1I38B4GFhC6r5peO3dsW95fBLwFOmv616/b6T+9/nAsvw8LE+fAHw/Dx8OPJrfs0eB\naY2uu4P92ez1B/4JOCEPDwH+DWgGHgT2aXTN3bhv5+X/Uw8D9wAHNrrmOvbpBmA18Eb+/zUNOAs4\nK88X6cZlT+d/e+1+O7K3PerYt8/UvF8LgcM7W6cvtWFmZkX9vovJzMy2jAPCzMyKHBBmZlbkgDAz\nsyIHhJmZFTkgrE+QNFTSpxu4/Q/mq+sulrRdBes/OP+6tXX8hKqvzpuv7nl4lduwvs0BYX3FUNKV\nURvlk8CFEXFwRPyugvUfTPrdAQARMScizq9gO7WOJP3mxKzIv4OwPkFS69VEnwTmka71dHPka1ZJ\nug6YDQwj/chwMPBO4PqI+Fpucxrwd6TLVz8AfDoiNrXZztHAhaTL0DwE/C1wOuky5RuAX0TEJ2va\n7wDcRLokw9bAP0fEbEnvA74JvAN4Hjgz0uVFFuRt/xkp9Kbl8WZgO+A3pB+gbUf6kdZnJF0N/A44\nENgbmEr6dfZhpMtRn5lr+TDwtbzvTwNTI113ZznpOkkfAbYBTgZeI/1YahPQAnw2In5e/ztiA0Kj\nf/3nhx/1PICx1FznHvhT4Ed5eGfg16QP9TNJvybdlfQh+xjpV9rvIl1cbpu8zHeAM9psYwjpSp77\n5/FrgHPy8NXASYW6PgZ8r2Z8Z9KH8C+AEXnax4Er8/AC4Bt5eBLw0zx8JjX3Vqgdz9u+kfQr38nA\nS8Afk3oAFpGOPoaTri+2Q17mS8BX8vByUgBAOgpr/cX6V4EvNPq99aP3Pnr9xfrMSiLiXknfzlfo\n/Sjww4jYmC81My/yheQk3QJ8ANgIvA94KLfZjs0vFHgA8OuIeCqPzwLOBi7uoJRHgQslXUC6GcvP\nJf0R8EekKwdDOrKovZ7PLfl5ESn46nF7RISkR4E1EfFo3r8leR2jgYOA+/M2twV+2c42P1rnNm2A\nc0BYX3Yt6dzAKcBf10xv228apL++Z0XEP3awvi7fyCcinsrdSZOA8yTdBdwKLImIw9pZ7PX8vIn6\n/w+2LvNmzXDr+KC8rnkRcWo3btMGOJ+ktr7iZWDHNtOuBs4BiIglNdP/XOne19uR7lh3P+nCgCfl\nI47We2Pv3WZ9TwBjJe2Xx08H7u2oKEl7Aq9GxA9I5y7Gk86TjJB0WG6zTR03ZyntX1csBI5orV3S\n9pL2r3ib1s85IKxPyF1G90t6TNK/5GlrSJeYvqpN8/tIRxeLSV1PTRHxOPB/SHcWfIR0ovsPbiUZ\nEa+RTgD/W+7KeRP4biel/THwoKTFpBsinRvpFp0nARdIejjX0dm3he4BDspfo/14J203ExEtpPMW\nN+T9W0g6qd2R24G/zNv8YFe3af2fv8VkfZak7UnnAMZHxIY87Uzyt38aWZtZf+AjCOuTJH2I1CX0\nrdZwMLPu5SMIMzMr8hGEmZkVOSDMzKzIAWFmZkUOCDMzK3JAmJlZ0X8DSasNewEbHBUAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b7f28e5278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#creting a bar graph for number of emails in each class\n",
    "from matplotlib import pyplot as plt\n",
    "x=[-1,0,1]\n",
    "y=[592,297,111]\n",
    "\n",
    "plt.bar(x,y)\n",
    "plt.xlabel('type of sentiment')\n",
    "plt.ylabel('count')\n",
    "plt.title('number of emails in each class')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thanks for writing in Suriyah. \\n\\nWe can do a Skype call mid/late next week to discuss.\\n\\nHarp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi Suriyah!\\nThanks fir reaching out! I would be happy to talk but let's schedule a call for nex...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi Suriyah –\\n\\nI’m not really a decision maker here at Oracle. Your best bet would be to contac...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi Suriyah,\\n\\nPlease reach out end of second quarter and I'll make some time to discuss.\\n\\nRig...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am currently out of the office and will have limited e-Mail connectivity until I return on Tue...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  Thanks for writing in Suriyah. \\n\\nWe can do a Skype call mid/late next week to discuss.\\n\\nHarp...   \n",
       "1  Hi Suriyah!\\nThanks fir reaching out! I would be happy to talk but let's schedule a call for nex...   \n",
       "2  Hi Suriyah –\\n\\nI’m not really a decision maker here at Oracle. Your best bet would be to contac...   \n",
       "3  Hi Suriyah,\\n\\nPlease reach out end of second quarter and I'll make some time to discuss.\\n\\nRig...   \n",
       "4  I am currently out of the office and will have limited e-Mail connectivity until I return on Tue...   \n",
       "\n",
       "   category  \n",
       "0  Positive  \n",
       "1  Positive  \n",
       "2   Neutral  \n",
       "3  Negative  \n",
       "4   Neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#renaming the column class to category as class is a function in python so it will mistake class as function instead of \n",
    "#name\n",
    "df=df.rename(columns = {'class':'category'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    thanks for writing in suriyah. \\n\\nwe can do a skype call mid/late next week to discuss.\\n\\nharp...\n",
       "1    hi suriyah!\\nthanks fir reaching out! i would be happy to talk but let's schedule a call for nex...\n",
       "2    hi suriyah –\\n\\ni’m not really a decision maker here at oracle. your best bet would be to contac...\n",
       "3    hi suriyah,\\n\\nplease reach out end of second quarter and i'll make some time to discuss.\\n\\nrig...\n",
       "4    i am currently out of the office and will have limited e-mail connectivity until i return on tue...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting the text data into lower case and copying first column into a new panda series named only_text\n",
    "df['text'] = df['text'].str.lower()\n",
    "only_text = pd.DataFrame()\n",
    "only_text = df['text']\n",
    "only_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(only_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#removing stopwords\n",
    "#from nltk.corpus import stopwords\n",
    "#stop = stopwords.words('english')\n",
    "#only_text = only_text.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey traveling next weeks would love speak beginning dec. omer from krishnan sent tuesday november omer agiv subject speak omer sure. anytime between . . israel time wednesday works great could please suggest slot that s convenient you know best number reach you. best krishnan advisor enterprise tech contractiq web phone skype k curated essays mobile. articles from mobile trenches contributions techcrunch outsource magazine tue omer agiv wrote'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing stopwords\n",
    "#from nltk.corpus import stopwords\n",
    "#stop = stopwords.words('english')\n",
    "#only_text = only_text.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "#data cleaning\n",
    "#1. it is seen that there are hyperlinks present, so lets remove the hyperlinks\n",
    "#also taking only those words which have length less than 15letters and greater than 2 into 'a'\n",
    "p=re.compile(r'\\<http.+?\\>', re.DOTALL)\n",
    "\n",
    "\n",
    "a = []\n",
    "b=[]\n",
    "new_string = []\n",
    "for i in only_text:\n",
    "    b =re.sub(p, '', i)    \n",
    "    b = ' '.join([w for w in i.split() if len(w)<15])\n",
    "    b = ' '.join([w for w in b.split() if len(w)>3])\n",
    "    b = ' '.join(b.split())\n",
    "    a.append(b)\n",
    "\n",
    "#creating pandas dataframe and then converting it into panda series \n",
    "#removing all the characters except a-z cause we do not need numbers for sentiment analysis\n",
    "#removing words am, pm, suriyah krishnan\n",
    "only_text_pd = pd.DataFrame({'text':a})\n",
    "only_text_se = only_text_pd['text']\n",
    "only_text_se= only_text_se.str.replace('[^.a-z]',\" \")\n",
    "only_text_se = only_text_se.str.replace('am|pm|suriyah', \"\")\n",
    "#only_text_pd['cleaned'] = only_text_se\n",
    "\n",
    "\n",
    "b=[]\n",
    "a=[]\n",
    "\n",
    "#to remove spaces in between\n",
    "for i in only_text_se:\n",
    "    b = ' '.join(i.split())\n",
    "    a.append(b)\n",
    "    \n",
    "\n",
    "only_text_pd = pd.DataFrame({'text':a})\n",
    "only_text_se = only_text_pd['text']\n",
    "    \n",
    "\n",
    "\n",
    "#only_text_se = only_text_se.str.replace('am|pm|suriyah|krishnan|thank|email|hi|please', \"\")\n",
    "only_text_se[238] #processed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RE to find the sentences consisting the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#finding sentences containing the word \"best\"\n",
    "a=[]\n",
    "b=[]\n",
    "i=0\n",
    "\n",
    "for i in only_text_se:\n",
    "    b = re.findall(r\"([^.]*?love[^.]*\\.)\",i)\n",
    "    a.append(b)\n",
    "    \n",
    "\n",
    "matching_sentences = pd.DataFrame({'matched_sentences':a})\n",
    "#matching_sentences['matched_sentences'] = matching_sentences['matched_sentences'].str.replace(r\"\\s+\\(.*\\)\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To find the records containing a word\n",
    "Here I have took \"weeks\" as sample \n",
    "You can substitute with other words3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = \"weeks|months\"\n",
    "matching_records = only_text_pd[only_text_pd.text.str.contains(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>about call thursday morning we re eastern time know what works. regards steve palara director bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>chat thursday morning pacific. know that works. from krishnan sent wednesday valentin subject sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>thank you. regards lorraine from krishnan sent thursday lorraine palermo subject scaling enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>please type your reply above this line request received scaling engineering tes thank contacting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>thanks contact appreciate interest. right probably premature jump call i ll take look into info ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>thanks from krishnan reply to krishnan date thursday lior netzer subject mobile report contracti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>interested thank you. faherty direct . . support . .stage . from krishnan reply to krishnan date...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>interested this time. please check back months. please consider environment before printing this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>sorry interest. jerry jerry schmidt managing partner strategic business solutions we ve moved pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>agenda currently unlikely minimum months. kind regards jonathan sent from iphone krishnan wrote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>thank your email. longer involved with running auto it. best fife fife chairman this email conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>have long time relationship with te satisfied this time. wish well with your outreach. regards l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>hey traveling next weeks would love speak beginning dec. omer from krishnan sent tuesday novembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>will country next weeks. leadership interest they will touch. connecting with thank you a.m. wrote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>i ve resigned from sport chalet will leaving year. since were acquired about months parent compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>interest this time. from krishnan sent friday subject scaling engineering tes glad re connect re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>from krishnan sent friday parks subject mobile report contractiq there glad re connect reached m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>please take your list. from krishnan sent friday michael zuercher subject mobile report contract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>dear just wanted know that alastair mills holiday weeks. kind regards alexis alastair mills chie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>thank your offer currently this relevant. will glad stay touch things along about months mon kri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>i ve forwarded your email member te their review. will them contact interested. this time there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>need your company s services. rick rick spickelmier inline image from krishnan sent friday rick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>yes that good. from krishnan sent tuesday michael subject scaling engineering tes michael glad r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>thanks your note . have forwarded head there alignment. very good place right having just made d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>hello please remove from your contact list. thanks barry barry knuttila svp marketing technology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>believe spoke already months back. client project sizes that serve don t really match with proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>thanks making contact business model. have co founders have aver years combined experience cover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>will looking into mobile develoent within next months. let s touch. friday eastern time sounds g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>thanks email. well brief little about current position. co founder startup ned maplegraph soluti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>sorry interested please take your regular emails. thanks laurence laurence o toole arrange your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>company reseller hrsmart. hrsmart recently acquired deltek. wouldn t have partnering sure deltek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>thanks . i ll save your contact info should hear need your services. sonia sonia gasparini digit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>hello. office week. best times after eastern each day. phil rist prosper from a.m. sent tuesday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>need anything like this right love learning hearing about thursday horrible next weeks crazy. ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>should speak someone group. that area. i ve been with company less than weeks sure that would be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>thanks your email. bizantra part prodextra systems. prodextra joint india company with significa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>sure help here. sorry. derek mon wrote derek glad re connect reached months back. thought share ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>thanks reaching out. still interested discussing internally. check back months. carl fremont glo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>thank sharing your report. might interested your services. next weeks probably come back you. be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>thanks your email. sorry don t quite understsnd what want from happy with call needs understand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>currently don t have need. handling develoent currently in house. traveling morning tomorrow. th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    text\n",
       "30   about call thursday morning we re eastern time know what works. regards steve palara director bu...\n",
       "54   chat thursday morning pacific. know that works. from krishnan sent wednesday valentin subject sc...\n",
       "60   thank you. regards lorraine from krishnan sent thursday lorraine palermo subject scaling enginee...\n",
       "63   please type your reply above this line request received scaling engineering tes thank contacting...\n",
       "87   thanks contact appreciate interest. right probably premature jump call i ll take look into info ...\n",
       "100  thanks from krishnan reply to krishnan date thursday lior netzer subject mobile report contracti...\n",
       "116  interested thank you. faherty direct . . support . .stage . from krishnan reply to krishnan date...\n",
       "123  interested this time. please check back months. please consider environment before printing this...\n",
       "192  sorry interest. jerry jerry schmidt managing partner strategic business solutions we ve moved pl...\n",
       "196      agenda currently unlikely minimum months. kind regards jonathan sent from iphone krishnan wrote\n",
       "202  thank your email. longer involved with running auto it. best fife fife chairman this email conta...\n",
       "220  have long time relationship with te satisfied this time. wish well with your outreach. regards l...\n",
       "238  hey traveling next weeks would love speak beginning dec. omer from krishnan sent tuesday novembe...\n",
       "242   will country next weeks. leadership interest they will touch. connecting with thank you a.m. wrote\n",
       "243  i ve resigned from sport chalet will leaving year. since were acquired about months parent compa...\n",
       "277  interest this time. from krishnan sent friday subject scaling engineering tes glad re connect re...\n",
       "308  from krishnan sent friday parks subject mobile report contractiq there glad re connect reached m...\n",
       "348  please take your list. from krishnan sent friday michael zuercher subject mobile report contract...\n",
       "349  dear just wanted know that alastair mills holiday weeks. kind regards alexis alastair mills chie...\n",
       "353  thank your offer currently this relevant. will glad stay touch things along about months mon kri...\n",
       "396  i ve forwarded your email member te their review. will them contact interested. this time there ...\n",
       "437  need your company s services. rick rick spickelmier inline image from krishnan sent friday rick ...\n",
       "448  yes that good. from krishnan sent tuesday michael subject scaling engineering tes michael glad r...\n",
       "452  thanks your note . have forwarded head there alignment. very good place right having just made d...\n",
       "469  hello please remove from your contact list. thanks barry barry knuttila svp marketing technology...\n",
       "522  believe spoke already months back. client project sizes that serve don t really match with proje...\n",
       "586  thanks making contact business model. have co founders have aver years combined experience cover...\n",
       "621  will looking into mobile develoent within next months. let s touch. friday eastern time sounds g...\n",
       "684  thanks email. well brief little about current position. co founder startup ned maplegraph soluti...\n",
       "696  sorry interested please take your regular emails. thanks laurence laurence o toole arrange your ...\n",
       "763  company reseller hrsmart. hrsmart recently acquired deltek. wouldn t have partnering sure deltek...\n",
       "824  thanks . i ll save your contact info should hear need your services. sonia sonia gasparini digit...\n",
       "827  hello. office week. best times after eastern each day. phil rist prosper from a.m. sent tuesday ...\n",
       "832  need anything like this right love learning hearing about thursday horrible next weeks crazy. ma...\n",
       "841  should speak someone group. that area. i ve been with company less than weeks sure that would be...\n",
       "860  thanks your email. bizantra part prodextra systems. prodextra joint india company with significa...\n",
       "911  sure help here. sorry. derek mon wrote derek glad re connect reached months back. thought share ...\n",
       "937  thanks reaching out. still interested discussing internally. check back months. carl fremont glo...\n",
       "939  thank sharing your report. might interested your services. next weeks probably come back you. be...\n",
       "972  thanks your email. sorry don t quite understsnd what want from happy with call needs understand ...\n",
       "983  currently don t have need. handling develoent currently in house. traveling morning tomorrow. th..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "matching_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text    hey traveling next weeks would love speak beginning dec. omer from krishnan sent tuesday november omer agiv subject speak omer sure. anytime between . . israel time wednesday works great could please suggest slot that s convenient you know best number reach you. best krishnan advisor enterprise tech contractiq web phone skype k curated essays mobile. articles from mobile trenches contributions techcrunch outsource magazine tue omer agiv wrote\n",
      "Name: 238, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "print(only_text_pd.iloc[238])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating series of pandas\n",
    "X= only_text_se\n",
    "y= df['category']\n",
    "\n",
    "#splitting the data into train and test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "#initiating count vectorizer and removing stop words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = CountVectorizer(stop_words='english',max_df=.3,min_df=0.02)\n",
    "\n",
    "#fitting train data and then transforming it to count matrix\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm\n",
    "\n",
    "#transforming the test data into the count matrix initiated for train data\n",
    "#no fitting takes place\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(alpha=5.2)\n",
    "\n",
    "#fitting the model into train data \n",
    "nb.fit(X_train_dtm, y_train)\n",
    "\n",
    "#predicting the model on train and test data\n",
    "y_pred_class_test = nb.predict(X_test_dtm)\n",
    "y_pred_class_train = nb.predict(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class_test))\n",
    "print(metrics.accuracy_score(y_train, y_pred_class_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred_class_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(y_train, y_pred_class_train, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb.predict_proba(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of records in each class in test data\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#falsely predicting it as negative sentiment sentence\n",
    "X_test[y_test < y_pred_class_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#example\n",
    "X_test[502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#falsely predicting it as non-negative sentence i.e positive and neutral sentence\n",
    "X_test[y_test > y_pred_class_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#example for false positive\n",
    "X_test[446]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#total number of unique words in train data\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lets take a look at first 50 tokens\n",
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the number of times each word appeared in each case\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the shape is 3 classifications and 4379 words\n",
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of times each token appears across all  negative sentiment tagged mails\n",
    "neg_token_count = nb.feature_count_[0, :]\n",
    "neg_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of times each token appears across all neutral tagged mails\n",
    "neutral_token_count = nb.feature_count_[1, :]\n",
    "neutral_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of times each token appears across all positive taggeed mails\n",
    "pos_token_count = nb.feature_count_[2, :]\n",
    "pos_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of tokens with their separate negative, neutral, positive counts of train vocabulary\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'negative':neg_token_count, 'neutral':neutral_token_count, 'positive':pos_token_count}).set_index('token')\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# examine 5 random DataFrame rows\n",
    "tokens.sample(5, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add 1 to all columns to avoid dividing by 0\n",
    "tokens['negative'] = tokens.negative + 1\n",
    "tokens['neutral'] = tokens.neutral + 1\n",
    "tokens['positive'] = tokens.positive + 1\n",
    "tokens.sample(5, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# convert the columns counts into percentages\n",
    "tokens['negative'] = tokens.negative / nb.class_count_[0]\n",
    "tokens['neutral'] = tokens.neutral/nb.class_count_[1]\n",
    "tokens['positive'] = tokens.positive / nb.class_count_[2]\n",
    "tokens.sample(5, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the ratio of negative with respect to other classes for each token\n",
    "tokens['negative_ratio'] = tokens.negative / (tokens.neutral+tokens.positive)\n",
    "tokens.sample(5, random_state=87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# examine the DataFrame sorted by negative_ratio\n",
    "tokens.sort_values('negative_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the ratio of positive with respect to other classes for each token\n",
    "tokens['positive_ratio'] = tokens.positive / (tokens.neutral+tokens.negative)\n",
    "tokens.sample(5, random_state=87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# examine the DataFrame sorted by positive ration\n",
    "tokens.sort_values('positive_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initiating count vectorizer and removing stop words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english',max_df=0.3)\n",
    "\n",
    "#fitting train data and then transforming it to count matrix\n",
    "mail_corpus = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mail_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_words = \"remove unsubscribe mailing interested changes list dont change\"\n",
    "negative_words = pd.Series(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_data = pd.DataFrame({'text':X.values})\n",
    "query = query_data.iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf.transform(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense = mail_corpus.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Applying tfidf on the user query\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "response = tfidf.transform(negative_words)\n",
    "similartext = list(map(lambda x: cosine_similarity(response, x),dense))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(similartext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Retrieving indices of top 25 most similar jobs to the selected user and storing in a list\n",
    "mostsimilarmails = sorted(range(len(similartext)), key=lambda i: similartext[i], reverse=True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Retrieving job ids from Jobs corpus for the top 25 most similar jobs to the selected user\n",
    "similarmails = pd.DataFrame(columns = ['ID', 'text'])\n",
    "count = 0\n",
    "for i in mostsimilarmails:\n",
    "    similarmails.set_value(count, 'ID',i)\n",
    "    similarmails.set_value(count,'text' ,only_text_se[i])\n",
    "    count += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarmails.to_csv('similarmail.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_text_se[883]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "seed=12\n",
    "logreg = LogisticRegression(C=0.016, random_state=12, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_log_pred_test = logreg.predict(X_test_dtm)\n",
    "y_log_pred_train = logreg.predict(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_log_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_train, y_log_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#precision , recall, f-score for train data\n",
    "precision_recall_fscore_support(y_train, y_log_pred_train, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#precision , recall, f-score for test data\n",
    "precision_recall_fscore_support(y_test, y_log_pred_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_log_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initializing reandom forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_clf = RandomForestClassifier(n_estimators=10)\n",
    "RF_clf.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predicting on train and test data\n",
    "y_rf_pred_test = RF_clf.predict(X_test_dtm)\n",
    "y_rf_pred_train = RF_clf.predict(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#good accuracy on test data\n",
    "metrics.accuracy_score(y_test, y_rf_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#overfitting on train dataa\n",
    "metrics.accuracy_score(y_train, y_rf_pred_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(y_test, y_rf_pred_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(y_train, y_log_pred_train, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not considering random forest as it is heavily overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for separating each category\n",
    "X= only_text_se\n",
    "y= df['category']\n",
    "\n",
    "\n",
    "Xy = pd.concat([X,y], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "neutral = Xy[Xy.category == 'Neutral']\n",
    "\n",
    "positive = Xy[Xy['category'] == \"Positive\"]\n",
    "\n",
    "negative = Xy[Xy['category'] == \"Negative\"]\n",
    "\n",
    "print(negative.shape)\n",
    "print(neutral.shape)\n",
    "print(positive.shape)\n",
    "\n",
    "\n",
    "Xy.groupby(['category'])['category'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#exporting to form word cloud\n",
    "neutral = neutral['text']\n",
    "positive = positive['text']\n",
    "negative= negative['text']\n",
    "\n",
    "positive.to_csv('positive.txt', header=None, index=None, sep=' ', mode='a')\n",
    "negative.to_csv('negative.txt', header=None, index=None, sep=' ', mode='a')\n",
    "neutral.to_csv('neutral.txt', header=None, index=None, sep=' ', mode='a')\n",
    "\n",
    "\n",
    "#importing the text format\n",
    "with open('neutral.txt', 'r') as input_file:\n",
    "    neutral = input_file.read()\n",
    "    \n",
    "with open('positive.txt', 'r') as input_file:\n",
    "    positive = input_file.read()\n",
    "    \n",
    "with open('negative.txt', 'r') as input_file:\n",
    "    negative = input_file.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#negative word cloud\n",
    "import wordcloud\n",
    "wc = wordcloud.WordCloud()\n",
    "img = wc.generate_from_text(negative)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#neutral word cloud\n",
    "import wordcloud\n",
    "wc = wordcloud.WordCloud()\n",
    "img = wc.generate_from_text(neutral)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#positive wordcloud\n",
    "import wordcloud\n",
    "wc = wordcloud.WordCloud()\n",
    "img = wc.generate_from_text(positive)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab_countvec = vect.get_feature_names()\n",
    "vocab_count = ' '.join(vocab_countvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Vocabulary  from count vectorizer wordcloud\n",
    "import wordcloud\n",
    "wc = wordcloud.WordCloud()\n",
    "img = wc.generate_from_text(vocab_count)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
